id: "compute/npu"
version: "1.0.0"
name: "NPU Inference Accelerator"
description: "Hardware-accelerated inference for embeddings and classification using OpenVINO."

category: system
level: intermediate

tags:
  - npu
  - openvino
  - inference
  - compute

dependencies: []

capabilities:
  - capability_id: "load_model"
    description: "Load and compile models with persistent caching."
  - capability_id: "infer_batch"
    description: "Execute batched inference with tensor management."
  - capability_id: "telemetry"
    description: "Report throughput and compiler latency."

permissions:
  filesystem: read
  network: []
  shell: none
